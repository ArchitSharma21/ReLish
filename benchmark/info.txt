Classification Datasets
=======================

- MNIST:
	- 60,000 training samples
	- 10,000 test samples
	- 28x28 mono images (8-bit)
	- 10 classes
	- {DATASET_PATH}/MNIST/raw/*

- Fashion MNIST:
	- 60,000 training samples
	- 10,000 test samples
	- 28x28 mono images (8-bit)
	- 10 classes
	- {DATASET_PATH}/FashionMNIST/raw/*

- CIFAR10:
	- 50,000 training samples
	- 10,000 validation samples
	- 32x32 RGB images
	- 10 classes
	- {DATASET_PATH}/CIFAR/cifar-10-batches-py/*

- CIFAR100:
	- 50,000 training samples
	- 10,000 validation samples
	- 32x32 RGB images
	- 100 classes
	- {DATASET_PATH}/CIFAR/cifar-100-python/*

- Tiny ImageNet:
	- 100,000 training samples
	- 10,000 validation samples
	- 64x64 RGB images
	- 200 classes
	- {DATASET_PATH}/TinyImageNet/tiny-imagenet-200/{train,val}/n*/*

- Imagenette:
	- 9,469 training samples
	- 3,925 validation samples
	- Shorter side 320 RGB images => 224x224 RGB images
	- 10 classes
	- {DATASET_PATH}/Imagenette/imagenette2-320/{train,val}/n*/*

- Imagewoof:
	- 9,025 training samples
	- 3,929 validation samples
	- Shorter side 320 RGB images => 224x224 RGB images
	- 10 classes
	- {DATASET_PATH}/Imagewoof/imagewoof2-320/{train,val}/n*/*

- Food-101:
	- 75,750 training samples
	- 25,250 validation samples
	- Longer side <=512 RGB images => 224x224 RGB images
	- 101 classes
	- {DATASET_PATH}/Food101/food-101/{images,meta}/*

- ImageNet1K:
	- 1,281,167 training samples
	- 50,000 validation samples
	- RGB images => 224x224 RGB images
	- 1000 classes
	- {DATASET_PATH}/ImageNet1K/ILSVRC-CLS/{train,val}/n*/*

- iNaturalist 2021:
	- 2,686,843 training samples (mini => 500,000 training samples)
	- 100,000 validation samples
	- RGB images => 224x224 RGB images
	- Classes: 3 kingdom, 13 phylum, 51 class, 273 order, 1103 family, 4884 genus, 10000 full
	- {DATASET_PATH}/iNaturalist/2021_{train,train_mini,valid}/*/*

Classification Models
=====================
Note: Number of parameters is affected by the number of input/output channels required for the dataset
Note: Number of parameters is evaluated for CIFAR10 (3 input channels, 10 output classes)

- FCNet:
	1,332,490 = fcnet-2
	1,480,714 = fcnet-3 = fcnet
	1,777,162 = fcnet-5
	2,221,834 = fcnet-8
	2,962,954 = fcnet-13

- SqueezeNet:
	727,626 = squeezenetp   (downscale /1-16 based on variant, default /16)
	727,626 = squeezenet1_1 (downscale /16 plus extra no-padding losses)

- ResNet (downscale /1-32 based on variant, default /32):
	 11,181,642 = resnet18
	 21,289,802 = resnet34
	 23,000,394 = resnext50_32x4d
	 23,528,522 = resnet50
	 42,520,650 = resnet101
	 58,164,298 = resnet152
	 66,854,730 = wide_resnet50_2
	 81,426,762 = resnext101_64x4d
	 86,762,826 = resnext101_32x8d
	124,858,186 = wide_resnet101_2

- Wide ResNet (downscale /4):
	   175,066 = wide1_resnet14_g3
	   272,282 = wide1_resnet20_g3
	   691,674 = wide2_resnet14_g3
	 1,079,642 = wide2_resnet20_g3
	 1,855,578 = wide2_resnet32_g3
	 2,748,890 = wide4_resnet14_g3
	 8,949,210 = wide4_resnet38_g3
	10,961,370 = wide8_resnet14_g3
	17,158,106 = wide8_resnet20_g3
	36,479,194 = wide10_resnet26_g3
	55,841,754 = wide10_resnet38_g3

- Wide ResNet (downscale /8):
	   701,018 = wide1_resnet18_g4
	 1,093,658 = wide1_resnet26_g4
	 2,792,154 = wide2_resnet18_g4
	 4,360,794 = wide2_resnet26_g4
	11,144,154 = wide4_resnet18_g4
	36,227,034 = wide4_resnet50_g4
	44,529,114 = wide8_resnet18_g4
	53,268,954 = wide6_resnet34_g4
	67,375,194 = wide6_resnet42_g4
	69,604,314 = wide8_resnet26_g4

- EfficientNet (downscale /1-32 based on variant, default /32):
	 20,190,298 = efficientnet_v2_s
	 52,871,166 = efficientnet_v2_m
	117,247,082 = efficientnet_v2_l

- ConvNeXt (downscale /1-32 based on variant, default /32, downscale affects num params due to kernel size changes):
	 27,827,818 = convnext_tiny
	 49,462,378 = convnext_small
	 87,576,714 = convnext_base
	196,245,706 = convnext_large

- Swin Transformer (downscale /1-32 based on variant, default /32, downscale affects num params due to kernel size changes):
	 27,527,044 = swin_t
	 48,844,948 = swin_s
	 86,753,474 = swin_b
	195,010,846 = swin_l

- Vision Transformer (downscale /1-32 based on variant, default /16, downscale significantly affects num params due to kernel size changes and hidden dimension changes, num params also depends explicitly on input image size via the position embedding parameters):
	 21,342,346 = vit_b-4
	 47,994,058 = vit_b-8
	 85,658,890 = vit_b-16 = vit_b
	 87,426,058 = vit_b-32
	 75,722,250 = vit_l-4
	170,280,202 = vit_l-8
	303,115,274 = vit_l-16 = vit_l
	305,471,498 = vit_l-32
	157,633,930 = vit_h-4
	354,507,850 = vit_h-8
	630,931,210 = vit_h-16 = vit_h
